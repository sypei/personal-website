<html>
	<head>
		<title>Siyou Pei - Expressive AR/VR sensing and interaction</title>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta name="description" content="Siyou Pei, AR/VR enthusiast, HCI researcher, Ph.D. student at HiLab@UCLA ECE with Prof Yang Zhang">


		<meta property="og:title" content="Siyou Pei - Expressive AR/VR sensing and interaction">
		<meta property="og:image" content="https://www.sypei.com/img/Siyou_table.jpg">
		<meta property="og:url" content="https://www.sypei.com">
		<meta property="og:description" content="Siyou Pei, AR/VR enthusiast, HCI researcher, Ph.D. student at HiLab@UCLA ECE with Prof Yang Zhang">
		<!-- <meta property='og:image:width' content='1200' /> -->
		<!-- <meta property='og:image:height' content='627' /> -->



		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
		<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.7/css/all.min.css"> -->
		<style type="text/css">
			.fa {
				  padding: 0px;
				  font-size: 20px;
				  width: 30px;
				  text-align: left;
				  text-decoration: none;
				  border-radius: 50%;
				}
			.social{
				width: 50px;
				font-size: 40px;
			}
			body {
				  font-family: Roboto, serif  !important;
				}
			h3,h4,.h3,.h4 {
			  font-family: Josefin Sans, serif  !important;
			  font-weight: bold;
				}
		.strong {
		            color: #F2A900;
		            font-weight: bold;
		        }
		.mini-header, .title_name, .email, .fa {
					color:#2D68C4; /*ucla blue*/
				}
		.navigator, .navigator a,.fa-trophy{
					color: #F2A900; /*ucla yellow*/
		}
		</style>
		<link href="https://fonts.googleapis.com/css?family=Josefin+Sans:wght@700" rel="stylesheet">

		<link href="css/bootstrap.min.css" rel="stylesheet">
		<link href="css/style.css" rel="stylesheet">
        <link rel="shortcut icon" href="img/ucla.ico" type="image/x-icon">
        <link rel="icon" href="img/ucla.ico" type="image/x-icon">
        <script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		
		  ga('create', 'G-35Q3FR2CS3', 'auto');
		  ga('send', 'pageview');

		</script>

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-35Q3FR2CS3"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-35Q3FR2CS3');
		</script>
	</head>
	<body>
		
		
		<div class="container-fluid">
			
			<div class="row">
				<BR><BR><BR>
			</div>

		 	<div class="row">
		      		<div class="col-xs-12 col-sm-12 col-md-5  col-md-offset-2 col-lg-5 col-lg-offset-2 line">		      		
		      		
						<a class="title_name" href="index.html" style="font-family: 'Josefin Sans'">Siyou Pei</a>				
						<BR>
						<span class = "navigator" style="font-size: 20px;font-family: 'Josefin Sans';">
			        			<a href="aboutme.html">About Me</a> - 
			        			<a href="research/Siyou_Pei_CV_07_2022.pdf" target="_blank">CV</a> - 
			        			<a href="https://hilab.dev">HiLab</a>
			        	</span>
			        	<br>
			        	<br>

			        	
						<a href="https://twitter.com/SiyouPei" class="fa fa-twitter social" title="twitter"></a>
						<a href="https://github.com/sypei"  class="fa fa-github social" title="github"></a>
						<a href="https://scholar.google.be/citations?user=WZd4DYAAAAAJ&hl=en" class="fa fa-graduation-cap social" title = "google scholar"></a>
						<p class='email'><b>sypei @ ucla dot edu</b></p>

						<BR>

			      		<!-- <P>
			      		AR/VR enthusiast<BR>HCI researcher<BR>Ph.D. student @<a href="https://hilab.dev">HiLab</a><BR>
			      		<a href="https://www.ee.ucla.edu/">Department of Electrical & Computer Engineering</a><BR>
			      		<a href="https://www.ucla.edu/">University of California, Los Angeles</a></P>      		
			      		<P>
			      		Have you ever felt <b>awkward or restrained</b> in existing Augmented Reality/Virtual Reality products?
			      		<BR>If you say yes, that enhances my research motivation. 
			      		<BR>My research allows people to have Expressive interactions and Fun experience in Augmented Reality/Virtual Reality, by developing novel interaction techniques and sensing technologies.
			        	</P> -->
					</div>
					<div class="col-xs-12 col-sm-12 col-md-3 col-lg-3 line">
		        		<img src="img/Siyou_table2.jpg"  class="img-responsive" width="600">
		      		</div>
			</div>

		</div>
		
		<div class="container-fluid">
			<div class="row">
				
				
			  <div class="col-xs-12 col-sm-6 col-md-5 col-md-offset-2 col-lg-5 col-lg-offset-2 line">
			  		<BR>
				  	<div class="row">
							<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12 pubbody"> 
							<span class="mini-header" id="projects" style="font-family: 'Josefin Sans'">
								Research</span>
							</div>
					</div>
					<BR>
					<div class="research-projects">
					
						<div class="row research-project" data-sort="2022-08-07">
		                    <div class="col-md-4">
		                    <br style="line-height: 10px">
		                    	<img src="research/ForceSight/ForceSight.png"  class="img-responsive"  width="600">
		                       <!-- <video loop muted playsinline poster="research/HandInterfaces/HandInterfaces.png" class="img-responsive"  width="600">
								   <source type="video/mp4" src="research/HandInterfaces/thumbnail.mp4">
								   <source type="video/webm" src="research/HandInterfaces/thumbnail.webm">
		                       </video> -->
							   
		                    </div>
		                    <div class="col-md-8">
		                        <h4>
									ForceSight: Non-Contact Force Sensing with Laser Speckle Imaging
		                        </h4>
		                        <p class="text-muted">
		                            Siyou Pei, Pradyumna Chari, Xue Wang, Xiaoying Yang, Achuta Kadambi, Yang Zhang (UIST 2022) <br />
		                        </p>
<!-- 		                        <p class="strong">
		                            <i class="fa fa-trophy"></i>Honorable Mention
		                        </p> -->
		                        
		                        <p>
									We present ForceSight, a non-contact force sensing approach using laser speckle imaging. Our key observation is that object surfaces deform in the presence of force. This deformation, though very minute, manifests as observable and discernible laser speckle shifts, which we leverage to sense the applied force. To investigate the feasibility of our approach, we conducted studies on a wide variety of materials. We also demonstrated the applicability with several example applications.  
		                        </p>
		                        <!-- <a href="https://dl.acm.org/doi/abs/10.1145/3491102.3501898" title="paper" target="_blank" class="fa fa-book" aria-hidden="true"></a> -->
		                        
		                        <a href="https://github.com/forcesight/ForceSight" target="_blank" title="code" class="fa fa-github" aria-hidden="true"></a>
		                        <!-- <a href="https://www.youtube.com/watch?v=ATg3M4QsfEQ" target="_blank" title="preview" class="fa fa-youtube-play" aria-hidden="true"></a> -->

		                        <!-- <a href="https://www.youtube.com/watch?v=LBIpIioWTaw" target="_blank" title="presentation" class="fa fa-microphone" aria-hidden="true"></a> -->
		                    </div>
							
							<div class="col-md-12"> 
								<hr class="dash">
							</div>
		                </div>
					
		                <div class="row research-project" data-sort="2022-05-02">
		                    <div class="col-md-4">
		                    <br style="line-height: 10px">
		                    	<img src="research/HandInterfaces/HandInterfaces.png"  class="img-responsive"  width="600">
		                       <!-- <video loop muted playsinline poster="research/HandInterfaces/HandInterfaces.png" class="img-responsive"  width="600">
								   <source type="video/mp4" src="research/HandInterfaces/thumbnail.mp4">
								   <source type="video/webm" src="research/HandInterfaces/thumbnail.webm">
		                       </video> -->
							   
		                    </div>
		                    <div class="col-md-8">
		                        <h4>
									Hand Interfaces: Using Hands to Imitate Objects in AR/VR for Expressive Interactions
		                        </h4>
		                        <p class="text-muted">
		                            Siyou Pei, Alexander Chen, Jaewook Lee, Yang Zhang (CHI 2022) <br />
		                        </p>
		                        <p class="strong">
		                            <i class="fa fa-trophy"></i>Honorable Mention
		                        </p>
		                        
		                        <p>
									A new interaction technique that lets users' hands become virtual objects by imitating the objects themselves. For example, a thumbs-up hand pose is used to mimic a joystick. We created a wide array of interaction designs around this idea to demonstrate its applicability in object retrieval and interactive control tasks. Collectively, we call these interaction designs Hand Interfaces. 
		                        </p>
		                        <a href="https://dl.acm.org/doi/abs/10.1145/3491102.3501898" title="paper" target="_blank" class="fa fa-book" aria-hidden="true"></a>
		                        
		                        <a href="https://github.com/handinterfaces/Hand-Interfaces" target="_blank" title="code" class="fa fa-github" aria-hidden="true"></a>
		                        <a href="https://www.youtube.com/watch?v=ATg3M4QsfEQ" target="_blank" title="preview" class="fa fa-youtube-play" aria-hidden="true"></a>

		                        <a href="https://www.youtube.com/watch?v=LBIpIioWTaw" target="_blank" title="presentation" class="fa fa-microphone" aria-hidden="true"></a>
		                    </div>
							
							<div class="col-md-12"> 
								<hr class="dash">
							</div>
		                </div>

		                <div class="row research-project" data-sort="2021-11-01">
		                	<br style="line-height: 10px">
		                    <div class="col-md-4">
		                       <video loop muted playsinline poster="research/AURITUS/AURITUS_Hardware.png" class="img-responsive" width="600">
								   <source type="video/mp4" src="research/AURITUS/thumbnail.mp4">
								   <source type="video/webm" src="research/AURITUS/thumbnail.webm">
		                       </video>
							   
		                    </div>
		                    <div class="col-md-8">
		                        <h4>
									AURITUS: An Open-Source Optimization Toolkit for Training and Development of Human Movement Models and Filters Using Earables
		                        </h4>
		                        <p class="text-muted">
		                            Swapnil Sayan Saha, Mr. Sandeep Singh Sandha, Siyou Pei, Vivek Jain, Mr. Ziqi Wang, Yuchen Li, Ankur Sarker, Prof. Mani Srivastava (IMWUT 2021) <br />
		                        </p>
		                        
		                        <p>
									 AURITUS is an extendable and open-source optimization toolkit designed to enhance and replicate earable applications. AURITUS handles data collection, pre-processing, and labeling tasks using graphical tools and provides a hardware-in-the-loop (HIL) optimizer and TinyML interface to develop lightweight and real-time machine-learning models for activity detection and filters for head-pose tracking.
		                        </p>
		                        <a href="research/AURITUS/imwut21_AURITUS.pdf" target="_blank" class="fa fa-book" aria-hidden="true"></a>&nbsp
		                       
		                        <a href="https://github.com/nesl/auritus" target="_blank" title="code" class="fa fa-github" aria-hidden="true"></a>
		                        <!-- <a href="" target="_blank" class="fa fa-youtube-play" aria-hidden="true"></a>&nbsp
		                        <a href="" target="_blank" class="fa fa-microphone" aria-hidden="true"></a> -->
		                    </div>
							
							<div class="col-md-12"> 
								<hr class="dash">
							</div>
		                </div>
							
						<div class="row research-project" data-sort="2021-07-24">
		                    <div class="col-md-4">
		        
		                       <img src="research/QuickQuestion/QuickQuestionRLmodel.png"  class="img-responsive"  width="600">
							   
		                    </div>
		                    <div class="col-md-8">
		                        <h4>
									Quick Question: Interrupting Users for Microtasks with Reinforcement Learning
		                        </h4>
		                        <p class="text-muted">
		                            Bo-Jhang Ho, Bharathan Balaji, Mehmet Koseoglu, Sandeep Sandha, Siyou Pei, Mani Srivastava (ICML 2021 Workshop on Human in the Loop Learning) <br/>
		                        </p>
		                        
		                        <p>
									Human attention is a scarce resource in modern computing. Quick Question explores use of reinforcement learning (RL) to schedule microtasks while minimizing user annoyance and compare its performance with supervised learning. We model the problem as a Markov decision process and use Advantage Actor Critic algorithm to identify interruptible moments.
		                        </p>
		                        <a href="https://www.icml-hill.com/_files/ugd/4ce291_9e413199c4e343459b0596ccb3d09738.pdf" target="_blank" class="fa fa-book" title="paper" aria-hidden="true"></a>&nbsp
		                      
		                        <a href="https://www.icml-hill.com/_files/ugd/4ce291_5f3f2c04924a4a4ba0fbac8b9d51fc78.pdf" target="_blank" class="fa fa-paperclip" title="slides" aria-hidden="true"></a>
		                    </div>
							
							<div class="col-md-12"> 
								<hr class="dash">
							</div>
		                </div>

						
		              
		            </div>
	            	</div>
				
			
				
			<div class="col-xs-12 col-sm-5 col-md-3 col-lg-3 line">
			  	<BR>
			  		
					<span class="mini-header" style="font-family: 'Josefin Sans';">
						<h3>News</h3>
					</span>
					<P>
						August 2022: Passed the <a href="https://www.ee.ucla.edu/ph-d-student-information/#oralexam" target="_blank">Oral Qualifying Examination</a> at Department of Electrical & Computer Engineering.
					</P>
					<P>
						May 2022: Reviewed UIST 2022 Papers.
					</P>
					<P>
						May 2022: Presented <a href="https://dl.acm.org/doi/abs/10.1145/3491102.3501898" target="_blank">Hand Interfaces</a> at CHI '22, New Orleans, LA.
					</P>
					<P>
						April 2022: Received CHI Honorable Mention Award for <a href="https://dl.acm.org/doi/abs/10.1145/3491102.3501898" target="_blank">Hand Interfaces</a>.
					</P>
					<P>
						April 2022: Reviewed CHI 2022 Late-Breaking Work.
					</P>
					<P>
						Mar 2022: Passed the <a href="https://www.ee.ucla.edu/ph-d-student-information/#preliminaryexam" target="_blank">Preliminary Exam</a> at Department of Electrical & Computer Engineering.
					</P>
					<P>
						Dec 2021: Turned in MS thesis and obtained the MS degree.
					</P>
					<P>
						Nov 2021: Reviewed CHI 2022 Papers.
					</P>
					<P>
						Feb 2021: Reviewed CHI 2021 Late-Breaking Work.
					</P>
					<P>
						Sept 2019: Started MS-Ph.D. program at University of California, Los Angeles.
					</P>			
				
				
					<br>
						
					<img src="img/bruin.png"  class="img-responsive" width=180>
					
					<br>
					<BR>
					<a class="twitter-timeline" 
					width="600"
					height="700"
					data-chrome="nofooter noheader noborder transparent"
					data-border-color="#ffffff"
					href="https://twitter.com/SiyouPei" 
					data-widget-id="515768611978223616">
						Tweets by @SiyouPei</a>
					<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
			  
			  		<P></P>
			  		<BR>
			  </div>
				
		</div>

		<BR>
		<small>&copy; Siyou Pei, <a href="https://github.com/sypei/personal_website">Source Code</a>.</small>
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    	<script src="js/bootstrap.min.js"></script>
	</body>
</html>